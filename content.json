{"meta":{"title":"Vince's Blog","subtitle":"还差的远呢","description":"还差的远呢","author":"毛靖文","url":"https://github.com/ZT-Vincent/ZT-Vincent.github.io"},"pages":[{"title":"categories","date":"2017-08-02T05:27:49.000Z","updated":"2017-08-02T05:32:25.868Z","comments":false,"path":"categories/index.html","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-08-02T05:23:08.000Z","updated":"2017-08-03T10:20:43.718Z","comments":false,"path":"tags/index.html","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"tensorflow学习笔记（三）——前馈神经网络","slug":"tf2","date":"2017-08-23T11:55:01.000Z","updated":"2017-09-12T06:57:26.029Z","comments":true,"path":"2017/08/23/tf2/","link":"","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/23/tf2/","excerpt":"对于机器学习而言，神经网络算是必学的内容了，也试着用tensorflow框架写了一下","text":"对于机器学习而言，神经网络算是必学的内容了，也试着用tensorflow框架写了一下 神经网络 神经网络即模仿生物学中的神经细胞进行接受信号，传播信号的过程。对于单个神经细胞，可能有n个输入以及m个输出，但对于复杂的神经网络，有多层神经网络，其中接受原始信号的为输入层，接受来自前面神经元输出的叫做隐藏层，隐藏层可以有多层，最后一层即是输出层。而前馈神经网络是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层．各层间没有反馈。 实现原理对于前馈神经网络的实现，利用的是教材中所给的数据input_data，为带有数字的图片。123#可在tensorflow库中导入from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True) 神经网络模型的构建12345678910111213141516171819202122232425262728# 首先定义设置网络层的函数，输入输出间均为线性关系def set_layer(inputs,in_size,out_size,layer_name,activate_function = None): # 权重和偏差量定义 W = tf.Variable(tf.random_uniform([in_size, out_size], -1.0, 1.0), name=&quot;W&quot; + layer_name) bias = tf.Variable(tf.constant(0.1, shape=[out_size]), name=&quot;bias_&quot;+ layer_name) # 线性模型 Wx_Plus_b = tf.matmul(inputs, W) + bias # 防止过拟合,keep_prob为每个元素的被保留概率 Wx_Plus_b = tf.nn.dropout(Wx_Plus_b, keep_prob) # 激活函数的使用 if activate_function is None: outputs = Wx_Plus_b else: outputs = activate_function(Wx_Plus_b) return outputs# 原始数据占位符xs = tf.placeholder(tf.float32, [None, n_input], name=&quot;input&quot;)ys = tf.placeholder(tf.float32, [None, n_classes], name=&quot;output&quot;)#保留概率keep_prob = tf.placeholder(tf.float32)# 神经网络的构建h1 = set_layer(xs, n_input, hidden_units1, &apos;hidden_layer_1&apos;, activate_function=tf.nn.tanh)#softmax和tf.nn.tanh为激活函数，都可用h2 = set_layer(h1, hidden_units1, hidden_units2, &apos;hidden_layer_2&apos;, activate_function=tf.nn.tanh)prediction = set_layer(h2, hidden_units2, n_classes, &apos;prediction_layer&apos;, activate_function=None)# 预测输出在用None无激活函数效果较好，也可用tf.nn.softmax，tf.nn.tanh等激活函数 训练指标的设置12345678910111213# cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction)))# 有看到资料说和下面一句意义相同，但实际上无法使用，# tf.nn.softmax_cross_entropy_with_logits将预测值转化为总和为一的概率值，并与实际值的计算交叉熵代价函数# tf.reduce_mean取均值cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=prediction))# 训练目标为使cross_entropy最小，使用梯度下降法进行训练train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)tf.summary.scalar(&apos;loss&apos;, cross_entropy)# 准确率correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))# 得到true false数据accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))# 求均值 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataimport timemnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)def set_layer(inputs,in_size,out_size,layer_name,activate_function = None): W = tf.Variable(tf.random_uniform([in_size, out_size], -1.0, 1.0), name=&quot;W&quot; + layer_name) bias = tf.Variable(tf.constant(0.1, shape=[out_size]), name=&quot;bias_&quot;+ layer_name) Wx_Plus_b = tf.matmul(inputs, W) + bias Wx_Plus_b = tf.nn.dropout(Wx_Plus_b, keep_prob)#防止过拟合,keep_prob为每个元素的被保留概率 if activate_function is None: outputs = Wx_Plus_b else: outputs = activate_function(Wx_Plus_b) return outputs## 参数设定hidden_layers = 1hidden_units1 = 200hidden_units2 = 50n_input = 784n_classes = 10learning_rate = 0.8## 神经网络的构建xs = tf.placeholder(tf.float32, [None, n_input], name=&quot;input&quot;)ys = tf.placeholder(tf.float32, [None, n_classes], name=&quot;output&quot;)keep_prob = tf.placeholder(tf.float32)h1 = set_layer(xs, n_input, hidden_units1, &apos;hidden_layer_1&apos;, activate_function=tf.nn.tanh)h2 = set_layer(h1, hidden_units1, hidden_units2, &apos;hidden_layer_2&apos;, activate_function=tf.nn.tanh)prediction = set_layer(h2, hidden_units2, n_classes, &apos;prediction_layer&apos;, activate_function=None)cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=prediction))train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)tf.summary.scalar(&apos;loss&apos;, cross_entropy)## 训练结果准确性correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))## 训练init = tf.initialize_all_variables()n_epochs = 40batch_size = 100with tf.Session() as sess: st = time.time() write = tf.summary.FileWriter(&apos;logs/&apos;, sess.graph) sess.run(init) for epoch in range(n_epochs): n_batch = int(mnist.train.num_examples / batch_size) for i in range(n_batch): batch_xs, batch_ys = mnist.train.next_batch(batch_size) sess.run(train_op, feed_dict=&#123;xs: batch_xs, ys: batch_ys, keep_prob:0.75&#125;) print (&apos;epoch&apos;, epoch, &apos;accuracy:&apos;, sess.run(accuracy, feed_dict=&#123;keep_prob:1.0, xs: mnist.test.images, ys: mnist.test.labels&#125;)) end = time.time() print (&apos;*&apos; * 30) print (&apos;training finish. cost time:&apos;, int(end-st) , &apos;seconds; accuracy:&apos;, sess.run(accuracy, feed_dict=&#123;keep_prob:1.0, xs: mnist.test.images, ys: mnist.test.labels&#125;))","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/机器学习/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"}]},{"title":"爬虫入门（一）","slug":"spider1","date":"2017-08-22T12:16:48.000Z","updated":"2017-08-22T15:45:22.708Z","comments":true,"path":"2017/08/22/spider1/","link":"","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/22/spider1/","excerpt":"一直以来都觉得爬虫是个很神奇的东西，既然已经学了Python，就准备自己来写写看","text":"一直以来都觉得爬虫是个很神奇的东西，既然已经学了Python，就准备自己来写写看 要用到的库123import urllib.requestimport urllib.parseimport re 在Python3较后的版本里，urllib库被封装在urllib.request，功能基本是类似的。 实现原理 爬虫的根本原理是模拟浏览器的行为，从而获取数据，然而现在web技术发展较快，浏览器也有不同的方法来得到数据，我看了些资料，主要就找到两种较常见的方法，一是后端静态加载的网页，通过获取其html源码来得到数据，二是利用JS异步请求动态加载的，通过请求得到JSON数据。 我首先试着获取静态加载的网页，在这里选择了58同城的二手房页面。可以在chrom浏览器开发者工具（F12）的network里看到网址信息 浏览器信息 模拟浏览器的所需的信息在Request Hearders（作为请求头）和Query String Parameters（作为请求发送的数据）123456789101112131415161718192021#url地址，这里选择了江干区二手房的第三页，不过其后天数据有随机性，并不固定url=&apos;http://hz.58.com/jianggan/ershoufang/pn3/?&apos;data=&#123;&#125;head=&#123;&#125;#请求头head[&apos;User-Agent&apos;]=&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.78 Safari/537.36&apos;#请求数据data[&apos;utm_source&apos;]=&apos;sem-sales-baidu-pc&apos;data[&apos;utm_campaign&apos;]=&apos;sell&apos;data[&apos;utm_medium&apos;]=&apos;cpc&apos;data[&apos;spm&apos;]=&apos;62854932425.16537920598&apos;data[&apos;PGTID&apos;]=&apos;0d300000-0000-0a0c-8067-a60b6ee48510&apos;data[&apos;ClickID&apos;]=1data=urllib.parse.urlencode(data).encode(&apos;utf-8&apos;)req=urllib.request.Request(url,data,head,method=&apos;GET&apos;)#将请求得到的响应（response）下载下来req = urllib.request.urlopen(req)my_data = req.read() 在获得了html源码数据后，如何提取所需的内容，通常是利用正则表达式，这对于没认真学正则的我来说还是挺头疼的，主要是要提取标签内的数据，同时对于byte，str，list，obj，dict等数据结构要会转换运用，才能得到想要的内容。 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import urllib.requestimport urllib.parseimport re#保存HTML源码def saveFile(data): path = &quot;D:\\\\python\\\\Spider\\\\58\\\\html.out&quot; f = open(path,&apos;wb&apos;) f.write(data) f.close()#所需要的数据，考虑到正则匹配的水平太差，就挑了好拿的部分content = &#123;&#125;content[&apos;tingshi&apos;] = []content[&apos;daxiao&apos;] = []content[&apos;chaoxiang&apos;] = []content[&apos;louceng&apos;] = []content[&apos;jiedao&apos;] = []content[&apos;price&apos;] = []name = [&apos;tingshi&apos;,&apos;daxiao&apos;,&apos;chaoxiang&apos;,&apos;louceng&apos;,&apos;jiedao&apos;]#正则匹配式res_tr1 = r&quot;&lt;ul class=&apos;house-list-wrap&apos;&gt;(.*?)&lt;/ul&gt;&quot;res_tr2 = r&quot;&lt;span&gt;(.*?)&lt;/span&gt;&quot;res_price = r&apos;&lt;b&gt;(.*?)&lt;/b&gt;&apos;res_jiedao = r&apos;&lt;a&gt;(.*?)&lt;/a&gt;&apos;def getdata(datalist): num = -1 for x in datalist: num = num + 1 num = num%6; if num == 5: continue if num &lt; 4: print(x) content[name[num]].append(x) if num == 4: content[name[num]].append(re.findall(res_jiedao,x,re.S|re.M))url=&apos;http://hz.58.com/jianggan/ershoufang/pn3/?&apos;data=&#123;&#125;head=&#123;&#125;head[&apos;User-Agent&apos;]=&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.78 Safari/537.36&apos;data[&apos;utm_source&apos;]=&apos;sem-sales-baidu-pc&apos;data[&apos;utm_campaign&apos;]=&apos;sell&apos;data[&apos;utm_medium&apos;]=&apos;cpc&apos;data[&apos;spm&apos;]=&apos;62854932425.16537920598&apos;data[&apos;PGTID&apos;]=&apos;0d300000-0000-0a0c-8067-a60b6ee48510&apos;data[&apos;ClickID&apos;]=1data=urllib.parse.urlencode(data).encode(&apos;utf-8&apos;)req=urllib.request.Request(url,data,head,method=&apos;GET&apos;)req = urllib.request.urlopen(req)my_data = req.read()saveFile(my_data)#匹配出ul标签内数据my_strdata = bytes.decode(my_data)m_list1 = re.findall(res_tr1,my_strdata,re.S|re.M)m_tr1 = &quot;&quot;.join(m_list1)content[&apos;price&apos;] = re.findall(res_price,m_tr1,re.S|re.M)m_list2 = re.findall(res_tr2,m_tr1,re.S|re.M)getdata(m_list2)print(content) html源码 逐个观察数据 在实际操作中，还是出现了一些状况，对于ul标签内的每一份二手房数据，部分会缺失一部分信息（如建造时间，地铁距离未标明），在提取的时候还是会导致出错，由于该网站后台提供数据是有一定随机性的，尝试几次后，有时能完整提取，有时候就会因为数据的不完整性，导致爬取格式出错。","categories":[{"name":"Python","slug":"Python","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/Python/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/爬虫/"}]},{"title":"tensorflow学习笔记（二）——数据类型","slug":"tf1","date":"2017-08-17T03:18:54.000Z","updated":"2017-08-17T07:03:19.730Z","comments":true,"path":"2017/08/17/tf1/","link":"","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/17/tf1/","excerpt":"看了官网的教程，先跑了第一个例程，大概学习了tensorflow的几种数据类型以及程序流程","text":"看了官网的教程，先跑了第一个例程，大概学习了tensorflow的几种数据类型以及程序流程 数据类型tensorflow的数据以张量的形式构成，其形状和类型的设定和实际数值的写入是分开的，主要有常量，变量和占位符三种类型：这是基本的python数组12a = [[1., 2., 3.], [4., 5., 6.]]#普通的python数组 对于tensorflow常量1234567b1 = tf.constant(3,dtype=tf.float32,name = &apos;b1&apos;)b2 = tf.constant(a,dtype=tf.float32)#tensorflow常量的赋值只能为定值，dtype定义了其数据为浮点型,name为其命名#也可用b1 = tf.constant(3,&quot;float&quot;)定义#测试后发现tf.zeros([5]),tf.ones([5,5]),tf.random_uniform([5, 5], -2.0, 2.0)创建的也为常量数据#其实质和constant相同，zeros等为常量的名称#我理解为constant常量可用于给变量或占位符进行赋值 对于tensorflow变量1234567c1 = tf.Variable(a, dtype = tf.float32,name = &apos;c1&apos;)c2 = tf.Variable(b1, dtype = tf.float32)c3 = tf.Variable(tf.ones([5,5]))c4 = tf.Variable(tf.random_uniform([5, 5], -2.0, 2.0))#tensorflow变量可直接使用python普通数组赋值，也可用tensorflow常量#若所赋的初始化值已定义数据类型，则可以不再定义#使用变量需先初始化，在计算中其值是不断变换的，一般形状大小设置固定，用作被训练的权重等 对于tensorflow占位符12345678x1 = tf.placeholder(tf.float32)x2 = tf.placeholder(tf.float32,[None,3])x3 = tf.placeholder(dtype = tf.float32,shape = (2,2))#占位符是事先设定好，用来接受外部输入的一个值，一般用作训练样本和标签的数据#shape定义的形状大小，None代表任意大小，也可先不定义，与输入数据相同print(sess.run([x1,x2,x3], feed_dict = &#123;x1:[[1,2],[1,2],[3,4]],x2:[[1,2,3],[2,6,4]],x3:[[1,2],[3,4]]&#125;))#在进行运算时，将数据从外部输入 完整代码1234567891011121314151617181920212223242526272829import tensorflow as tfa = [[1., 2., 3.], [4., 5., 6.]]b1 = tf.constant(3,dtype=tf.float32,name = &apos;b1&apos;)b2 = tf.constant(a,dtype=tf.float32)print(b1)print(b2)c1 = tf.Variable(a, dtype = tf.float32,name = &apos;c1&apos;)c2 = tf.Variable(b1, dtype = tf.float32)c3 = tf.Variable(tf.ones([5,5]))c4 = tf.Variable(tf.random_uniform([5, 5], -2.0, 2.0))x1 = tf.placeholder(tf.float32)x2 = tf.placeholder(tf.float32,[None,3])x3 = tf.placeholder(dtype = tf.float32,shape = (2,2))sess = tf.Session()#创建图init = tf.global_variables_initializer()sess.run(init)#将所有变量初始化print(sess.run([b1,b2]))print(sess.run([c1,c2,c3,c4]))print(sess.run([x1,x2,x3], feed_dict = &#123;x1:[[1,2],[1,2],[3,4]],x2:[[1,2,3],[2,6,4]],x3:[[1,2],[3,4]]&#125;))","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/机器学习/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"}]},{"title":"tensorflow学习笔记（一）——安装与配置","slug":"tf0","date":"2017-08-16T14:32:54.000Z","updated":"2017-08-17T02:59:50.182Z","comments":true,"path":"2017/08/16/tf0/","link":"","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/16/tf0/","excerpt":"tensorflow是谷歌所开发的用于深度学习，并完全开源的一个库，我也想通过学习tensorflow来逐渐了解深度学习以及机器学习。和以往学过的内容一样，第一步要做的就是配环境。","text":"tensorflow是谷歌所开发的用于深度学习，并完全开源的一个库，我也想通过学习tensorflow来逐渐了解深度学习以及机器学习。和以往学过的内容一样，第一步要做的就是配环境。 tensorflow版本详情 tensorflow在今年支持windows上的安装使用了，如今最新为1.3版本，可能还不是很通用，更多使用的是1.1和1.2版本，根据官网所说，仅支持python3.5版本，不过我使用的python3.6也安装成功了，应该是3.5以后版本都能用。在windows上使用tensorflow，还分为CPU和GPU两版，GPU需要NVIDIA显卡支持，同时安装也更麻烦，不够考虑到CPU的运算速度，还是决定安装GPU版本。 安装所需环境为成功安装tensorflow的GPU版本，一共需要在电脑安装： python3.5或以后版本 pip3 VS2015（官网现在没这条，先装了总没错） CUDA8.0 cuDNNv5.1 安装（踩坑）详情以上所需软件也可在官网下载安装，需要注意的有，python安装时需要添加PATH变量以便使用pip快速导入包。然后可使用pip指令快速安装tensorflow库pip3 install --upgrade tensorflow-gpu虽然不知道为什么，我一开始下载的时候一直报错，可能是网络不稳定吧，总之最后还是能安装的。VS2015在线安装可能会失败，最好先翻墙。主要的困难在于CUDA和cuDNN，CUDA安装完后可在命令行输入指令查看nvcc -VcuDNN下载后需要将文件添加入PATH环境变量，也可将解压后文件夹中的三个子文件夹中的文件分别复制添加至cuda所安装位置下的文件夹，默认安装路径是：C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0，其中对应的bin，include，x64文件夹中。 测试代码安装完成后可在cmd指令界面打开python，输入以下代码进行测试：123456import tensorflow as tfa = tf.random_normal((10, 10))b = tf.random_normal((10, 5))c = tf.matmul(a, b)sess = tf.InteractiveSession()sess.run(c) 能跑就基本是安装成功了 示例结果","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/机器学习/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"}]},{"title":"写在最开始","slug":"firstblog","date":"2017-08-02T14:56:45.653Z","updated":"2017-08-16T14:54:52.560Z","comments":true,"path":"2017/08/02/firstblog/","link":"","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/02/firstblog/","excerpt":"博客终于搭建好了，也算是难得完成了一件想要做的事，希望接下来能完成更多的目标吧。","text":"博客终于搭建好了，也算是难得完成了一件想要做的事，希望接下来能完成更多的目标吧。 关于 我 我是一个正在杭州读大学的学生，自认为对编程还算比较有兴趣，最终还是选择了进入计算机专业学习。在学校的这两年，带着美好的幻想去尝试过许多东西，似乎每次在开始的时候还是能有一定的进展，最终却总是不能达到最初想要的结果，可能自己还是太菜了吧。 关于 博客 说起来，想要有一个自己的博客已经很久了，却发现总是有各种事情要忙，导致把这个博客的搭建一直拖到了这个暑假。 一开始呢，是想着自己来写代码实现一个博客的，为此决定去学了JavaScript（放弃了PHP和Java），同样，一开始还是很认真的，从JS的基础语法，到ES6标准，对异步操作纠结了很久，前端选择了Vue框架，后端也学了nodeJS。然而学了一阵以后，发现好像事情没有那么简单，无论是Vue还是node，真要学好的话，这个坑还是有点深。预估了下学这些所需的时间，并且面前又出现了别的选项。于是还是放弃了这个想法。 最终我还是选用了hexo来快速搭建一个博客，按照教程，稍微学下git的用法，还是很快就完成了。这让我不得不说，开源的力量还是很大的。 关于 未来 曾经花了不少精力在ACM的学习与参赛上，然而也没能获得令自己满意的成果，也参加了创业类的项目，过程与结果也都不尽如人意。有一阵在学Web开发的内容，发现和很早就一心做Web的同学相比还是欠缺不少，还是没能说服自己就踏实地做Web开发就好了，可能是脑子里还是有一些不切实际的幻想吧，于是在近期又参加了数学建模的比赛，虽然说不好又会翻车。 想了想，关于未来，似乎还是有许多空白的地方，那就慢慢来吧。目前决定去学习算法方面的内容，就目前来看，机器学习还是比较热门的，个人也有些兴趣。虽然也知道，以后可能要为一时的冲动买单。不过反正也不是第一次了，想要就去做嘛，重要的不是能有什么好处或者非要取得什么成就，而是能真正专心的做些东西吧。 既然已经有了自己的博客，能将之后所学到的内容记录下来，那就日常先来一个flag，希望能时常更博，并且能逐个完成自己所定的目标吧。","categories":[{"name":"日常","slug":"日常","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/日常/"}],"tags":[{"name":"flag","slug":"flag","permalink":"https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/flag/"}]}]}