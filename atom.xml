<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Vince&#39;s Blog</title>
  <subtitle>还差的远呢</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/"/>
  <updated>2017-09-12T06:57:26.029Z</updated>
  <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/</id>
  
  <author>
    <name>毛靖文</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tensorflow学习笔记（三）——前馈神经网络</title>
    <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/23/tf2/"/>
    <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/23/tf2/</id>
    <published>2017-08-23T11:55:01.000Z</published>
    <updated>2017-09-12T06:57:26.029Z</updated>
    
    <content type="html"><![CDATA[<p>对于机器学习而言，神经网络算是必学的内容了，也试着用tensorflow框架写了一下<br><a id="more"></a></p>
<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>　　神经网络即模仿生物学中的神经细胞进行接受信号，传播信号的过程。对于单个神经细胞，可能有n个输入以及m个输出，但对于复杂的神经网络，有多层神经网络，其中接受原始信号的为输入层，接受来自前面神经元输出的叫做隐藏层，隐藏层可以有多层，最后一层即是输出层。而<a href="https://baike.baidu.com/item/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/7580523?fr=aladdin" target="_blank" rel="external">前馈神经网络</a>是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层．各层间没有反馈。</p>
<h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>对于前馈神经网络的实现，利用的是教材中所给的数据input_data，为带有数字的图片。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#可在tensorflow库中导入</div><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</div></pre></td></tr></table></figure></p>
<p>神经网络模型的构建<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># 首先定义设置网络层的函数，输入输出间均为线性关系</div><div class="line">def set_layer(inputs,in_size,out_size,layer_name,activate_function = None):</div><div class="line">    # 权重和偏差量定义</div><div class="line">    W = tf.Variable(tf.random_uniform([in_size, out_size], -1.0, 1.0), name=&quot;W&quot; + layer_name)</div><div class="line">    bias =  tf.Variable(tf.constant(0.1, shape=[out_size]), name=&quot;bias_&quot;+ layer_name)</div><div class="line">    # 线性模型</div><div class="line">    Wx_Plus_b = tf.matmul(inputs, W) + bias</div><div class="line">    # 防止过拟合,keep_prob为每个元素的被保留概率</div><div class="line">    Wx_Plus_b = tf.nn.dropout(Wx_Plus_b, keep_prob)</div><div class="line">    # 激活函数的使用</div><div class="line">    if activate_function is None:</div><div class="line">        outputs = Wx_Plus_b</div><div class="line">    else:</div><div class="line">        outputs = activate_function(Wx_Plus_b)</div><div class="line">    return outputs</div><div class="line"></div><div class="line"># 原始数据占位符</div><div class="line">xs = tf.placeholder(tf.float32, [None, n_input], name=&quot;input&quot;)</div><div class="line">ys = tf.placeholder(tf.float32, [None, n_classes], name=&quot;output&quot;)</div><div class="line">#保留概率</div><div class="line">keep_prob = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line"># 神经网络的构建</div><div class="line">h1 = set_layer(xs, n_input, hidden_units1, &apos;hidden_layer_1&apos;, activate_function=tf.nn.tanh)</div><div class="line">#softmax和tf.nn.tanh为激活函数，都可用</div><div class="line">h2 = set_layer(h1, hidden_units1, hidden_units2, &apos;hidden_layer_2&apos;, activate_function=tf.nn.tanh)</div><div class="line">prediction = set_layer(h2, hidden_units2, n_classes, &apos;prediction_layer&apos;, activate_function=None)</div><div class="line"># 预测输出在用None无激活函数效果较好，也可用tf.nn.softmax，tf.nn.tanh等激活函数</div></pre></td></tr></table></figure></p>
<p>训练指标的设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction)))</div><div class="line"># 有看到资料说和下面一句意义相同，但实际上无法使用，</div><div class="line"># tf.nn.softmax_cross_entropy_with_logits将预测值转化为总和为一的概率值，并与实际值的计算交叉熵代价函数</div><div class="line"># tf.reduce_mean取均值</div><div class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=prediction))</div><div class="line"># 训练目标为使cross_entropy最小，使用梯度下降法进行训练</div><div class="line">train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)</div><div class="line">tf.summary.scalar(&apos;loss&apos;, cross_entropy)</div><div class="line"># 准确率</div><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))</div><div class="line"># 得到true false数据</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line"># 求均值</div></pre></td></tr></table></figure></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">import time</div><div class="line">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</div><div class="line"></div><div class="line">def set_layer(inputs,in_size,out_size,layer_name,activate_function = None):</div><div class="line">    W = tf.Variable(tf.random_uniform([in_size, out_size], -1.0, 1.0), name=&quot;W&quot; + layer_name)</div><div class="line">    bias =  tf.Variable(tf.constant(0.1, shape=[out_size]), name=&quot;bias_&quot;+ layer_name)</div><div class="line">    Wx_Plus_b = tf.matmul(inputs, W) + bias</div><div class="line">    Wx_Plus_b = tf.nn.dropout(Wx_Plus_b, keep_prob)#防止过拟合,keep_prob为每个元素的被保留概率</div><div class="line">    if activate_function is None:</div><div class="line">        outputs = Wx_Plus_b</div><div class="line">    else:</div><div class="line">        outputs = activate_function(Wx_Plus_b)</div><div class="line">    return outputs</div><div class="line"></div><div class="line">## 参数设定</div><div class="line">hidden_layers = 1</div><div class="line">hidden_units1 = 200</div><div class="line">hidden_units2 = 50</div><div class="line">n_input = 784</div><div class="line">n_classes = 10</div><div class="line">learning_rate = 0.8</div><div class="line">## 神经网络的构建</div><div class="line">xs = tf.placeholder(tf.float32, [None, n_input], name=&quot;input&quot;)</div><div class="line">ys = tf.placeholder(tf.float32, [None, n_classes], name=&quot;output&quot;)</div><div class="line">keep_prob = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">h1 = set_layer(xs, n_input, hidden_units1, &apos;hidden_layer_1&apos;, activate_function=tf.nn.tanh)</div><div class="line">h2 = set_layer(h1, hidden_units1, hidden_units2, &apos;hidden_layer_2&apos;, activate_function=tf.nn.tanh)</div><div class="line">prediction = set_layer(h2, hidden_units2, n_classes, &apos;prediction_layer&apos;, activate_function=None)</div><div class="line"></div><div class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=prediction))</div><div class="line">train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)</div><div class="line">tf.summary.scalar(&apos;loss&apos;, cross_entropy)</div><div class="line">## 训练结果准确性</div><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line"></div><div class="line">## 训练</div><div class="line">init = tf.initialize_all_variables()</div><div class="line">n_epochs = 40</div><div class="line">batch_size = 100</div><div class="line">with tf.Session() as sess:</div><div class="line">    st = time.time()</div><div class="line">    write = tf.summary.FileWriter(&apos;logs/&apos;, sess.graph)</div><div class="line">    sess.run(init)</div><div class="line">    for epoch in range(n_epochs):</div><div class="line">        n_batch = int(mnist.train.num_examples / batch_size)</div><div class="line">        for i in range(n_batch):</div><div class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</div><div class="line">            sess.run(train_op, feed_dict=&#123;xs: batch_xs, ys: batch_ys, keep_prob:0.75&#125;)</div><div class="line">        print (&apos;epoch&apos;, epoch, &apos;accuracy:&apos;, sess.run(accuracy, feed_dict=&#123;keep_prob:1.0, xs: mnist.test.images, ys: mnist.test.labels&#125;))</div><div class="line">    end = time.time()</div><div class="line">    print (&apos;*&apos; * 30)</div><div class="line">    print (&apos;training finish. cost time:&apos;, int(end-st) , &apos;seconds; accuracy:&apos;, sess.run(accuracy, feed_dict=&#123;keep_prob:1.0, xs: mnist.test.images, ys: mnist.test.labels&#125;))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于机器学习而言，神经网络算是必学的内容了，也试着用tensorflow框架写了一下&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>爬虫入门（一）</title>
    <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/22/spider1/"/>
    <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/22/spider1/</id>
    <published>2017-08-22T12:16:48.000Z</published>
    <updated>2017-08-22T15:45:22.708Z</updated>
    
    <content type="html"><![CDATA[<p>一直以来都觉得爬虫是个很神奇的东西，既然已经学了Python，就准备自己来写写看<br><a id="more"></a></p>
<h1 id="要用到的库"><a href="#要用到的库" class="headerlink" title="要用到的库"></a>要用到的库</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">import urllib.request</div><div class="line">import urllib.parse</div><div class="line">import re</div></pre></td></tr></table></figure>
<p>在Python3较后的版本里，urllib库被封装在urllib.request，功能基本是类似的。</p>
<h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>　　爬虫的根本原理是模拟浏览器的行为，从而获取数据，然而现在web技术发展较快，浏览器也有不同的方法来得到数据，我看了些资料，主要就找到两种较常见的方法，一是后端静态加载的网页，通过获取其html源码来得到数据，二是利用JS异步请求动态加载的，通过请求得到JSON数据。<br>　　我首先试着获取静态加载的网页，在这里选择了58同城的二手房页面。可以在chrom浏览器开发者工具（F12）的network里看到网址信息<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/spider/chrom.png" alt="浏览器信息" title="">
                </div>
                <div class="image-caption">浏览器信息</div>
            </figure><br>　　模拟浏览器的所需的信息在Request Hearders（作为请求头）和Query String Parameters（作为请求发送的数据）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">#url地址，这里选择了江干区二手房的第三页，不过其后天数据有随机性，并不固定</div><div class="line">url=&apos;http://hz.58.com/jianggan/ershoufang/pn3/?&apos;</div><div class="line"></div><div class="line">data=&#123;&#125;</div><div class="line">head=&#123;&#125;</div><div class="line">#请求头</div><div class="line">head[&apos;User-Agent&apos;]=&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.78 Safari/537.36&apos;</div><div class="line"></div><div class="line">#请求数据</div><div class="line">data[&apos;utm_source&apos;]=&apos;sem-sales-baidu-pc&apos;</div><div class="line">data[&apos;utm_campaign&apos;]=&apos;sell&apos;</div><div class="line">data[&apos;utm_medium&apos;]=&apos;cpc&apos;</div><div class="line">data[&apos;spm&apos;]=&apos;62854932425.16537920598&apos;</div><div class="line">data[&apos;PGTID&apos;]=&apos;0d300000-0000-0a0c-8067-a60b6ee48510&apos;</div><div class="line">data[&apos;ClickID&apos;]=1</div><div class="line"></div><div class="line">data=urllib.parse.urlencode(data).encode(&apos;utf-8&apos;)</div><div class="line">req=urllib.request.Request(url,data,head,method=&apos;GET&apos;)</div><div class="line">#将请求得到的响应（response）下载下来</div><div class="line">req = urllib.request.urlopen(req)</div><div class="line">my_data = req.read()</div></pre></td></tr></table></figure></p>
<p>　　在获得了html源码数据后，如何提取所需的内容，通常是利用正则表达式，这对于没认真学正则的我来说还是挺头疼的，主要是要提取标签内的数据，同时对于byte，str，list，obj，dict等数据结构要会转换运用，才能得到想要的内容。</p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">import urllib.request</div><div class="line">import urllib.parse</div><div class="line">import re</div><div class="line"></div><div class="line">#保存HTML源码</div><div class="line">def saveFile(data):</div><div class="line">    path = &quot;D:\\python\\Spider\\58\\html.out&quot;</div><div class="line">    f = open(path,&apos;wb&apos;)</div><div class="line">    f.write(data)</div><div class="line">    f.close()</div><div class="line"></div><div class="line">#所需要的数据，考虑到正则匹配的水平太差，就挑了好拿的部分</div><div class="line">content = &#123;&#125;</div><div class="line">content[&apos;tingshi&apos;] = []</div><div class="line">content[&apos;daxiao&apos;] = []</div><div class="line">content[&apos;chaoxiang&apos;] = []</div><div class="line">content[&apos;louceng&apos;] = []</div><div class="line">content[&apos;jiedao&apos;] = []</div><div class="line">content[&apos;price&apos;] = []</div><div class="line"></div><div class="line">name = [&apos;tingshi&apos;,&apos;daxiao&apos;,&apos;chaoxiang&apos;,&apos;louceng&apos;,&apos;jiedao&apos;]</div><div class="line"></div><div class="line">#正则匹配式</div><div class="line">res_tr1 = r&quot;&lt;ul class=&apos;house-list-wrap&apos;&gt;(.*?)&lt;/ul&gt;&quot;</div><div class="line">res_tr2 = r&quot;&lt;span&gt;(.*?)&lt;/span&gt;&quot;</div><div class="line">res_price = r&apos;&lt;b&gt;(.*?)&lt;/b&gt;&apos;</div><div class="line">res_jiedao = r&apos;&lt;a&gt;(.*?)&lt;/a&gt;&apos;</div><div class="line"></div><div class="line"></div><div class="line">def getdata(datalist):</div><div class="line">    num = -1</div><div class="line">    for x in datalist:</div><div class="line">        num = num + 1</div><div class="line">        num = num%6;</div><div class="line">        if num == 5:</div><div class="line">            continue</div><div class="line">        if num &lt; 4:</div><div class="line">            print(x)</div><div class="line">            content[name[num]].append(x)</div><div class="line">        if num == 4:</div><div class="line">            content[name[num]].append(re.findall(res_jiedao,x,re.S|re.M))</div><div class="line"></div><div class="line"></div><div class="line">url=&apos;http://hz.58.com/jianggan/ershoufang/pn3/?&apos;</div><div class="line">data=&#123;&#125;</div><div class="line">head=&#123;&#125;</div><div class="line"></div><div class="line">head[&apos;User-Agent&apos;]=&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.78 Safari/537.36&apos;</div><div class="line"></div><div class="line"></div><div class="line">data[&apos;utm_source&apos;]=&apos;sem-sales-baidu-pc&apos;</div><div class="line">data[&apos;utm_campaign&apos;]=&apos;sell&apos;</div><div class="line">data[&apos;utm_medium&apos;]=&apos;cpc&apos;</div><div class="line">data[&apos;spm&apos;]=&apos;62854932425.16537920598&apos;</div><div class="line">data[&apos;PGTID&apos;]=&apos;0d300000-0000-0a0c-8067-a60b6ee48510&apos;</div><div class="line">data[&apos;ClickID&apos;]=1</div><div class="line"></div><div class="line">data=urllib.parse.urlencode(data).encode(&apos;utf-8&apos;)</div><div class="line">req=urllib.request.Request(url,data,head,method=&apos;GET&apos;)</div><div class="line"></div><div class="line">req = urllib.request.urlopen(req)</div><div class="line">my_data = req.read()</div><div class="line">saveFile(my_data)</div><div class="line"></div><div class="line">#匹配出ul标签内数据</div><div class="line">my_strdata = bytes.decode(my_data)</div><div class="line">m_list1 =  re.findall(res_tr1,my_strdata,re.S|re.M)</div><div class="line"></div><div class="line">m_tr1 = &quot;&quot;.join(m_list1)</div><div class="line">content[&apos;price&apos;] =  re.findall(res_price,m_tr1,re.S|re.M)</div><div class="line"></div><div class="line">m_list2 =  re.findall(res_tr2,m_tr1,re.S|re.M)</div><div class="line">getdata(m_list2)</div><div class="line"></div><div class="line">print(content)</div></pre></td></tr></table></figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/spider/58html.png" alt="html源码" title="">
                </div>
                <div class="image-caption">html源码</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/spider/58data.png" alt="逐个观察数据" title="">
                </div>
                <div class="image-caption">逐个观察数据</div>
            </figure>
<p>　　在实际操作中，还是出现了一些状况，对于ul标签内的每一份二手房数据，部分会缺失一部分信息（如建造时间，地铁距离未标明），在提取的时候还是会导致出错，由于该网站后台提供数据是有一定随机性的，尝试几次后，有时能完整提取，有时候就会因为数据的不完整性，导致爬取格式出错。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直以来都觉得爬虫是个很神奇的东西，既然已经学了Python，就准备自己来写写看&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/Python/"/>
    
    
      <category term="爬虫" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow学习笔记（二）——数据类型</title>
    <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/17/tf1/"/>
    <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/17/tf1/</id>
    <published>2017-08-17T03:18:54.000Z</published>
    <updated>2017-08-17T07:03:19.730Z</updated>
    
    <content type="html"><![CDATA[<p>看了官网的教程，先跑了第一个例程，大概学习了tensorflow的几种数据类型以及程序流程<br><a id="more"></a></p>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><p>tensorflow的数据以张量的形式构成，其形状和类型的设定和实际数值的写入是分开的，主要有常量，变量和占位符三种类型：<br>这是基本的python数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">a = [[1., 2., 3.], [4., 5., 6.]]</div><div class="line">#普通的python数组</div></pre></td></tr></table></figure></p>
<p>对于tensorflow常量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">b1 = tf.constant(3,dtype=tf.float32,name = &apos;b1&apos;)</div><div class="line">b2 = tf.constant(a,dtype=tf.float32)</div><div class="line">#tensorflow常量的赋值只能为定值，dtype定义了其数据为浮点型,name为其命名</div><div class="line">#也可用b1 = tf.constant(3,&quot;float&quot;)定义</div><div class="line">#测试后发现tf.zeros([5]),tf.ones([5,5]),tf.random_uniform([5, 5], -2.0, 2.0)创建的也为常量数据</div><div class="line">#其实质和constant相同，zeros等为常量的名称</div><div class="line">#我理解为constant常量可用于给变量或占位符进行赋值</div></pre></td></tr></table></figure></p>
<p>对于tensorflow变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">c1 = tf.Variable(a, dtype = tf.float32,name = &apos;c1&apos;)</div><div class="line">c2 = tf.Variable(b1, dtype = tf.float32)</div><div class="line">c3 = tf.Variable(tf.ones([5,5]))</div><div class="line">c4 = tf.Variable(tf.random_uniform([5, 5], -2.0, 2.0))</div><div class="line">#tensorflow变量可直接使用python普通数组赋值，也可用tensorflow常量</div><div class="line">#若所赋的初始化值已定义数据类型，则可以不再定义</div><div class="line">#使用变量需先初始化，在计算中其值是不断变换的，一般形状大小设置固定，用作被训练的权重等</div></pre></td></tr></table></figure></p>
<p>对于tensorflow占位符<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">x1 = tf.placeholder(tf.float32)</div><div class="line">x2 = tf.placeholder(tf.float32,[None,3])</div><div class="line">x3 = tf.placeholder(dtype = tf.float32,shape = (2,2))</div><div class="line">#占位符是事先设定好，用来接受外部输入的一个值，一般用作训练样本和标签的数据</div><div class="line">#shape定义的形状大小，None代表任意大小，也可先不定义，与输入数据相同</div><div class="line"></div><div class="line">print(sess.run([x1,x2,x3], feed_dict = &#123;x1:[[1,2],[1,2],[3,4]],x2:[[1,2,3],[2,6,4]],x3:[[1,2],[3,4]]&#125;))</div><div class="line">#在进行运算时，将数据从外部输入</div></pre></td></tr></table></figure></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">a = [[1., 2., 3.], [4., 5., 6.]]</div><div class="line"></div><div class="line">b1 = tf.constant(3,dtype=tf.float32,name = &apos;b1&apos;)</div><div class="line">b2 = tf.constant(a,dtype=tf.float32)</div><div class="line">print(b1)</div><div class="line">print(b2)</div><div class="line"></div><div class="line">c1 = tf.Variable(a, dtype = tf.float32,name = &apos;c1&apos;)</div><div class="line">c2 = tf.Variable(b1, dtype = tf.float32)</div><div class="line">c3 = tf.Variable(tf.ones([5,5]))</div><div class="line">c4 = tf.Variable(tf.random_uniform([5, 5], -2.0, 2.0))</div><div class="line"></div><div class="line">x1 = tf.placeholder(tf.float32)</div><div class="line">x2 = tf.placeholder(tf.float32,[None,3])</div><div class="line">x3 = tf.placeholder(dtype = tf.float32,shape = (2,2))</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">#创建图</div><div class="line">init = tf.global_variables_initializer()</div><div class="line">sess.run(init)</div><div class="line">#将所有变量初始化</div><div class="line"></div><div class="line">print(sess.run([b1,b2]))</div><div class="line"></div><div class="line">print(sess.run([c1,c2,c3,c4]))</div><div class="line"></div><div class="line">print(sess.run([x1,x2,x3], feed_dict = &#123;x1:[[1,2],[1,2],[3,4]],x2:[[1,2,3],[2,6,4]],x3:[[1,2],[3,4]]&#125;))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看了官网的教程，先跑了第一个例程，大概学习了tensorflow的几种数据类型以及程序流程&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow学习笔记（一）——安装与配置</title>
    <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/16/tf0/"/>
    <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/16/tf0/</id>
    <published>2017-08-16T14:32:54.000Z</published>
    <updated>2017-08-17T02:59:50.182Z</updated>
    
    <content type="html"><![CDATA[<p>tensorflow是谷歌所开发的用于深度学习，并完全开源的一个库，我也想通过学习tensorflow来逐渐了解深度学习以及机器学习。和以往学过的内容一样，第一步要做的就是配环境。<br><a id="more"></a></p>
<h1 id="tensorflow版本详情"><a href="#tensorflow版本详情" class="headerlink" title="tensorflow版本详情"></a>tensorflow版本详情</h1><p>　　<a href="www.tensorflow.org">tensorflow</a>在今年支持windows上的安装使用了，如今最新为1.3版本，可能还不是很通用，更多使用的是1.1和1.2版本，根据官网所说，仅支持python3.5版本，不过我使用的python3.6也安装成功了，应该是3.5以后版本都能用。在windows上使用tensorflow，还分为CPU和GPU两版，GPU需要NVIDIA显卡支持，同时安装也更麻烦，不够考虑到CPU的运算速度，还是决定安装GPU版本。</p>
<h1 id="安装所需环境"><a href="#安装所需环境" class="headerlink" title="安装所需环境"></a>安装所需环境</h1><p>为成功安装tensorflow的GPU版本，一共需要在电脑安装：</p>
<ol>
<li><a href="www.python.org">python3.5</a>或以后版本</li>
<li>pip3</li>
<li><a href="http://download.microsoft.com/download/B/4/8/B4870509-05CB-447C-878F-2F80E4CB464C/vs_community.exe" target="_blank" rel="external">VS2015</a>（官网现在没这条，先装了总没错）</li>
<li><a href="http://pan.baidu.com/s/1slqIVk5" target="_blank" rel="external">CUDA8.0</a></li>
<li><a href="http://pan.baidu.com/s/1sl2UfSh" target="_blank" rel="external">cuDNNv5.1</a></li>
</ol>
<h1 id="安装（踩坑）详情"><a href="#安装（踩坑）详情" class="headerlink" title="安装（踩坑）详情"></a>安装（踩坑）详情</h1><p>以上所需软件也可在官网下载安装，需要注意的有，python安装时需要添加PATH变量以便使用pip快速导入包。然后可使用pip指令快速安装tensorflow库<br><code>pip3 install --upgrade tensorflow-gpu</code><br>虽然不知道为什么，我一开始下载的时候一直报错，可能是网络不稳定吧，总之最后还是能安装的。<br>VS2015在线安装可能会失败，最好先翻墙。<br>主要的困难在于CUDA和cuDNN，CUDA安装完后可在命令行输入指令查看<br><code>nvcc -V</code><br>cuDNN下载后需要将文件添加入PATH环境变量，也可将解压后文件夹中的三个子文件夹中的文件分别复制添加至cuda所安装位置下的文件夹，默认安装路径是：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0，其中对应的bin，include，x64文件夹中。</p>
<h1 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h1><p>安装完成后可在cmd指令界面打开python，输入以下代码进行测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">a = tf.random_normal((10, 10))</div><div class="line">b = tf.random_normal((10, 5))</div><div class="line">c = tf.matmul(a, b)</div><div class="line">sess = tf.InteractiveSession()</div><div class="line">sess.run(c)</div></pre></td></tr></table></figure></p>
<p>能跑就基本是安装成功了<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/t2.png" alt="示例结果" title="">
                </div>
                <div class="image-caption">示例结果</div>
            </figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;tensorflow是谷歌所开发的用于深度学习，并完全开源的一个库，我也想通过学习tensorflow来逐渐了解深度学习以及机器学习。和以往学过的内容一样，第一步要做的就是配环境。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>写在最开始</title>
    <link href="https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/02/firstblog/"/>
    <id>https://github.com/ZT-Vincent/ZT-Vincent.github.io/2017/08/02/firstblog/</id>
    <published>2017-08-02T14:56:45.653Z</published>
    <updated>2017-08-16T14:54:52.560Z</updated>
    
    <content type="html"><![CDATA[<p>博客终于搭建好了，也算是难得完成了一件想要做的事，希望接下来能完成更多的目标吧。<br><a id="more"></a></p>
<h1 id="关于-我"><a href="#关于-我" class="headerlink" title="关于 我"></a>关于 我</h1><p>　　我是一个正在杭州读大学的学生，自认为对编程还算比较有兴趣，最终还是选择了进入计算机专业学习。在学校的这两年，带着美好的幻想去尝试过许多东西，似乎每次在开始的时候还是能有一定的进展，最终却总是不能达到最初想要的结果，可能自己还是太菜了吧。</p>
<h1 id="关于-博客"><a href="#关于-博客" class="headerlink" title="关于 博客"></a>关于 博客</h1><p>　　说起来，想要有一个自己的博客已经很久了，却发现总是有各种事情要忙，导致把这个博客的搭建一直拖到了这个暑假。<br>　　一开始呢，是想着自己来写代码实现一个博客的，为此决定去学了JavaScript（放弃了PHP和Java），同样，一开始还是很认真的，从JS的基础语法，到ES6标准，对异步操作纠结了很久，前端选择了Vue框架，后端也学了nodeJS。然而学了一阵以后，发现好像事情没有那么简单，无论是Vue还是node，真要学好的话，这个坑还是有点深。预估了下学这些所需的时间，并且面前又出现了别的选项。于是还是放弃了这个想法。<br>　　最终我还是选用了hexo来快速搭建一个博客，按照教程，稍微学下git的用法，还是很快就完成了。这让我不得不说，开源的力量还是很大的。</p>
<h1 id="关于-未来"><a href="#关于-未来" class="headerlink" title="关于 未来"></a>关于 未来</h1><p>　　曾经花了不少精力在ACM的学习与参赛上，然而也没能获得令自己满意的成果，也参加了创业类的项目，过程与结果也都不尽如人意。有一阵在学Web开发的内容，发现和很早就一心做Web的同学相比还是欠缺不少，还是没能说服自己就踏实地做Web开发就好了，可能是脑子里还是有一些不切实际的幻想吧，于是在近期又参加了数学建模的比赛，虽然说不好又会翻车。<br>　　想了想，关于未来，似乎还是有许多空白的地方，那就慢慢来吧。目前决定去学习算法方面的内容，就目前来看，机器学习还是比较热门的，个人也有些兴趣。虽然也知道，以后可能要为一时的冲动买单。不过反正也不是第一次了，想要就去做嘛，重要的不是能有什么好处或者非要取得什么成就，而是能真正专心的做些东西吧。<br>　　既然已经有了自己的博客，能将之后所学到的内容记录下来，那就日常先来一个flag，希望能时常更博，并且能逐个完成自己所定的目标吧。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;博客终于搭建好了，也算是难得完成了一件想要做的事，希望接下来能完成更多的目标吧。&lt;br&gt;
    
    </summary>
    
      <category term="日常" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/categories/%E6%97%A5%E5%B8%B8/"/>
    
    
      <category term="flag" scheme="https://github.com/ZT-Vincent/ZT-Vincent.github.io/tags/flag/"/>
    
  </entry>
  
</feed>
